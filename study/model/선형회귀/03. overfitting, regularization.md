<img width="490" alt="캡처" src="https://user-images.githubusercontent.com/34879309/73619874-9a781b00-4672-11ea-9b83-59e168dd9535.PNG">

<img width="253" alt="캡처" src="https://user-images.githubusercontent.com/34879309/73619909-c4c9d880-4672-11ea-8797-4e212e8849de.PNG">

# overfitting 극복
```
더 많은 데이터를 활용한다.
Feature의 개수를 줄인다.
적절히 Parameter를 선정한다.
Regularization !
```

# Regularization (정규화)
## L2 regularization
<img width="459" alt="캡처" src="https://user-images.githubusercontent.com/34879309/73620068-897bd980-4673-11ea-8a16-206c9611606e.PNG">
```
규제에 j=1 부터인 이유는
θ0 즉, 절편에는 규제를 주지 않는다는 것이다.
θ0에 규제를 주면 처음 y값이 변형되므로
```

## L1 regularization
<img width="378" alt="캡처" src="https://user-images.githubusercontent.com/34879309/73620234-3fdfbe80-4674-11ea-9152-76016b9eb27d.PNG">
<img width="321" alt="캡처" src="https://user-images.githubusercontent.com/34879309/73620262-59810600-4674-11ea-9aa7-01999a87f377.PNG">
```
s가 커기면 마름모와 원의 크기가 커져서
타원의 중심(sgb 최적값)에 도달한다.
여기서 타원은 cost값이 같은 것 끼리 연결한것
```

```
L2는 한점에서 만나고
L1은 여러 점에서 만날 수있다.
```


